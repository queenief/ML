{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Building an Image Classifier from Scratch\n",
    "\n",
    "The main goal of this lab is to create an image classifier from scratch using the Keras package. You will create a binary classifier based on an object type of your choice. The classifier will accept images and then predict whether or not a given image contains that object. For example, if you chose your object to be a cat, then the classifier would accept images and predict 1 if it believes there is a cat in the image or a 0 if not. \n",
    "\n",
    "You will build and train a classifier in two ways: \n",
    "- first using the original data set that you create, and \n",
    "- second, using data augmentation techniques. \n",
    "\n",
    "**Grading:** \n",
    "\n",
    "50% of the grade will come from error-free code that accomplishes all the steps outlined in the instructions for each part of this lab and written in Python/Keras. The other 50% will come from the comments associated with that code, where the comments explain what the code is doing and why it is important to the overall objective. Thus, comments like \"split the data\" or \"train the model\" would receive a grade of 0 as they do not indicate any understanding.\n",
    "\n",
    "**Research Required:** \n",
    "\n",
    "To complete this lab successfully you will need to some research. At the very least, you will need to implement the `ImageDataGenerator` class and the `.flow_from_directory` methods that can be reviewed in the [Keras documentation](https://keras.io/api/preprocessing/#image-data-preprocessing). You may also find it helpful to use `os` package (which you already have installed) as that let's you work with files and folders similar to using the command line interface (use `import os` to get access to these commands). For example, to get your current working directory you would use: \n",
    "```python\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "```\n",
    "\n",
    "**What to submit:**\n",
    "- A copy of this notebook with:\n",
    "    - Error-free code in Python/Keras\n",
    "    - All code cells executed and output visible\n",
    "- Include a zipped file of your images\n",
    "\n",
    "\n",
    "\n",
    "## Part 1: Prep Work\n",
    "### Choose an Object\n",
    "\n",
    "You may choose any object other than a cat. Try to think of an object that is readily available for taking pictures and, preferably, outdoors, as that will add to the natural variability to the data.\n",
    "\n",
    "### Create a Dataset\n",
    "\n",
    "Take 80 pictures of the chosen object and 80 pictures of other things that are not your object. Each group member should supply a roughly equal number of pictures so as to increase variability in your dataset. \n",
    "\n",
    "From these 160 images you will create a training set (50 object/50 not object), a validation set (15 object/15 not object), and a test set (15 object/15 not object).\n",
    "\n",
    "It's best if your dataset is diverse, so take pictures of the chosen **object** with, for example, different lighting, from different angles, different distances from camera, different examples of the same type of object. Similarly for the **not object** images: try to include a variety of objects in different ways. \n",
    "\n",
    "You will then need to organize your dataset into folders so the images can be read directly from a Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using the Original Data\n",
    "\n",
    "### Dataset Verification\n",
    "\n",
    "You should verify that the training, validation, and test sets have the correct number of images (the `os` functions should help with this) and that the data is organized in a folder structure that will work with your image data generators. \n",
    "\n",
    "### Dataset Loading and Processing with Image Data Generators\n",
    "\n",
    "You should now create image data generators for your training, validation, and test datasets that will allow you to feed them into your model in batches. The images should be resized to 148x148 pixels and scaled so all pixel values are between 0 and 1. \n",
    "\n",
    "You should then use the training data generator to print out some examples of the training images and corresponding labels. (`matplotlib` should work for this and the fact that an image data generator has a `.next()` method.) \n",
    "\n",
    "### Create and Evaluate a Model\n",
    "\n",
    "Build a convolutional neural network and use the validation loss and accuracy to select the best architecture and hyperparameters so that you can maximize the validation accuracy. \n",
    "\n",
    "Any overfitting should be addressed; that is, if your model begins overfitting after epoch 3, you should not quote validation accuracy after epoch 15. And, appropriate attempts should be made to reduce/eliminate the overfitting to improve overall model generalizability. \n",
    "\n",
    "### Report Accuracy on Test Set \n",
    "\n",
    "Your final step is to make predictions using the test set and report the final test set accuracy. It may be helpful to use `batch_size=1` for this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using Data Augmentation\n",
    "\n",
    "### Dataset Verification\n",
    "\n",
    "You should verify that the training, validation, and test sets have the correct number of images (the `os` functions should help with this) and that the data is organized in a folder structure that will work with your image data generators. \n",
    "\n",
    "### Dataset Loading and Processing with Create Image Data Generators\n",
    "\n",
    "You should now create image data generators for your training, validation, and test datasets that will allow you to feed them into your model in batches. The images should be resized to 148x148 pixels and scaled so all pixel values are between 0 and 1. \n",
    "\n",
    "### Add Data Augmentation \n",
    "\n",
    "You should now add data augmentation to your training data generator. All available types of augmentation should be used. \n",
    "\n",
    "Print an image and examples of the same image augmented in different ways. (The `.load_img()` and `.flow()` methods may be helpful here.)\n",
    "\n",
    "### Create and Evaluate a Baseline Model\n",
    "\n",
    "Use the best model from **Part 2** to train with the augmented data and evaluate on the validation data to get a baseline accuracy for the new model trained on the augmented dataset. \n",
    "\n",
    "### Tune the Model\n",
    "\n",
    "With a more complex training set, you may be able to improve the accuracy through adjustments to the baseline model architecture and tuning the hyperparameters. \n",
    "\n",
    "### Report Accuracy on Test Set \n",
    "\n",
    "Your final step is to make predictions using the test set and report the final test set accuracy. It may be helpful to use `batch_size=1` for this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
